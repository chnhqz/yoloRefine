### 一、目标检测简介

#### 1.什么是目标检测？

目标检测（Object Detection）的任务是找出图像中所有感兴趣的目标（物体），确定他们的类别和位置，是计算机视觉领域的核心问题之一。由于各类物体有不同的外观、形状和姿态，加上成像时光照、遮挡等因素的干扰，目标检测一直是计算机视觉领域最具挑战的问题。

计算机视觉中关于图像识别有四大类人物：

- 分类-Classification：解决“是什么？”的问题，即给定一张图片或一段视频判断里面包含什么类别的目标。
- 定位-Location：解决“在哪里？”的问题，即定位出这个目标的位置。
- 检测-Detection：解决“在哪里？是什么？”的问题，即定位出这个目标的位置并且知道目标物体是什么。
- 分割-Segmentation：分为实例的分割（Instance-level）和场景分割（Scene-level），解决“每一个像素属于哪个目标物或场景”的问题。

<img src="/Users/huangqiuzhao/python/yoloRefine/md文件/img/目标检测简介/截屏2023-10-28 14.56.09.png" style="zoom:50%;" />

所以，目标检测是一个分类、回归问题的叠加。

#### 2.目标检测的核心问题

- 分类问题：即图片（或某个区域）中的图像属于哪个类别。
- 定位问题：目标可能出现在图像的任何位置。
- 大小问题：目标有各种不同的大小。
- 形状问题：目标可能有各种不同的形状。

### 二、目标检测原理

目标检测分为两大系列（RCNN、YOLO系列），RCNN系列是基于区域检测的代表性算法，YOLO是基于区域提取的代表性算法，另外还有著名的SSD是基于前两个系列的改进。

#### 1.候选区域产生

##### 1.滑动窗口

通过滑窗法流程图可以很清晰理解其主要思路：首先对输入图像进行不同窗口大小的滑窗进行从左往右、从上到下的滑动。每次滑动时对当前窗口执行分类器（分类器是事先训练好的）。如果当前窗口得到较高的分类概率，则认为检测到了物体。对每个不同窗口大小的滑窗都进行检测后，会得到不同窗口检测到的物体标记，这些窗口大小会存在重复较高的部分，最后采用非极大值抑制（Non-Maximum Suppression,NMS）的方法进行筛选。最终，经过NMS筛选后获得检测到的物体。滑窗法简单易于理解，但是不同窗口大小进行全局搜索导致效率低下，而且设计窗口大小时候还需要考虑物体的长宽比。所以对于实时性要求较高的分类器，不推荐使用滑窗法。

> 非极大值抑制
>
> 非极大值抑制（Non-Maximum Suppression，NMS）是计算机视觉和图像处理领域中常用的技术，用于从图像或特征图中消除冗余信息，通常用于对象检测和边缘检测任务中。它的主要目的是消除检测到的多个重叠的候选目标，只保留最相关的目标，以提高检测精度。
>
> NMS 的工作原理通常如下：
>
> 1. 检测器或者算法会产生一系列候选目标框，每个框都伴随着一个置信度得分（通常是检测到目标的概率或者置信度）。
> 2. 对所有的候选目标框按照其置信度得分进行排序，通常是降序排列，得分最高的排在前面。
> 3. 从得分最高的候选目标框开始，遍历所有的候选框。对于当前处理的候选框，计算其与后续所有候选框的重叠区域（通常使用交并比，Intersection over Union，IoU来衡量）。
> 4. 如果某个候选框的IoU值高于预先设定的阈值（通常是一个较小的值，如0.5），则将该候选框抑制，不保留。如果IoU值低于阈值，就保留该候选框。
> 5. 继续遍历下一个候选框，重复步骤3和4，直到处理完所有的候选框。
>
> 通过执行这个过程，非极大值抑制会筛选出具有高置信度的目标框，并消除重叠的目标框，从而提高检测结果的准确性。这一方法在目标检测中经常用于筛选出最具代表性的检测结果，确保不同的候选框不会重复报告相同的目标。
>
> 非极大值抑制是许多目标检测算法的重要组成部分，如Faster R-CNN、YOLO（You Only Look Once）等，它有助于降低假阳性检测的数量，提高目标检测的鲁棒性。

<img src="/Users/huangqiuzhao/python/yoloRefine/md文件/img/目标检测简介/截屏2023-10-28 15.16.15.png" style="zoom:50%;" />

##### 2.选择性搜索

- 什么是选择性搜索？
  滑窗法类似穷举进行图像子区域搜索，但是一般情况下图像中大部分子区域是没有物体的。学者们自然而然想到只对图像中最有可能包含物体的区域进行搜索以此来提高计算效率。选择搜索（selective search,简称SS）方法是当下最为熟知的图像bounding boxes提取算法，由Koen E.A于2011年提出。
  选择搜索算法的主要思想：图像中物体可能存在的区域应该是有某些相似性或者连续性区域的。因此，选择搜索基于上面这一想法采用子区域合并的方法进行提取bounding boxes。首先，对输入图像进行分割算法产生许多小的子区域。其次，根据这些子区域之间相似性（相似性标准主要有颜色、纹理、大小等等）进行区域合并，不断的进行区域迭代合并。每次迭代过程中对这些合并区域做bounding boxes（外切矩形），这些子区域外切矩形就是通常所说的候选框。
  <img src="/Users/huangqiuzhao/python/yoloRefine/md文件/img/目标检测简介/截屏2023-10-28 15.31.46.png" style="zoom:50%;" />

- 选择搜索流程

  - Step0:生成区域集R
  - Step1:计算区域集R里每个相邻区域的相似度 $S=\{s_1,s_2,\dots\}$
  - Step2:找出相似度最高的两个区域，将其合并为新集，添加进R
  - Step3:从S中移除所有与Step2中有关的子集
  - Step4:计算新集与所有子集的相似度
  - Step5:跳至Step2，直至S为空

- 选择搜索优点

  - 计算效率优于滑窗法

  - 由于采用子区域合并策略，所以可以包含各种大小的疑似物体框

  - 合并区域相似的指标多样性，提高了检测物体的概率

### 三、目标检测模型

#### 1.R-CNN系列

**定义：**

  R-CNN（Regions with CNN features），是R-CNN系列的第一代算法，其实没有过多的使用“深度学习”思想，而是将“深度学习”和传统的“计算机视觉”的知识相结合。比如R-CNN pipeline中的第二步和第四步其实就属于传统的“计算机视觉”技术。使用selective search提取region proposals，使用SVM实现分类。

  > Region proposal是计算机视觉中用于目标检测和物体识别任务的重要概念。它指的是在图像中提出可能包含对象的区域或候选框，以便在这些候选框上进一步进行目标检测或识别操作。Region proposal的目标是减少在整个图像上进行目标检测或识别的计算量，从而提高算法的效率

  <img src="/Users/huangqiuzhao/python/yoloRefine/md文件/img/目标检测简介/截屏2023-10-28 16.21.20.png" style="zoom:50%;" />

**流程：**

- 预训练模型。选择一个预训练 （pre-trained）神经网络（如AlexNet、VGG）。
- 重新训练全连接层。使用需要检测的目标重新训练（re-train）最后全连接层（connected layer）。
- 提取 proposals并计算CNN 特征。利用选择性搜索（Selective Search）算法提取所有proposals（大约2000幅images），调整（resize/warp）它们成固定大小，以满足 CNN输入要求（因为全连接层的限制），然后将feature map 保存到本地磁盘。
- 训练SVM。利用feature map 训练SVM来对目标和背景进行分类（每个类一个二进制SVM）
- 边界框回归（Bounding boxes Regression）。训练将输出一些校正因子的线性回归分类器

> 计算卷积神经网络（CNN）特征涉及将输入图像通过一个预训练的CNN模型，并提取由网络的一个或多个层生成的特征。这些特征可用于各种计算机视觉任务，如图像分类、目标检测和图像分割。以下是计算CNN特征的一般步骤：
>
> 1. **选择预训练的CNN模型：** 首先选择一个预训练的CNN模型。常见选择包括VGG、ResNet、Inception和MobileNet等模型。您可以使用流行的深度学习框架，如TensorFlow、PyTorch或Keras，来访问这些预训练模型。
> 2. **预处理输入图像：** 预处理输入图像以满足所选CNN模型的要求。通常包括将图像调整为模型的输入尺寸、规范化像素值（通常在[0, 1]或[-1, 1]范围内），以及应用任何其他必要的预处理步骤（例如均值减法）。
> 3. **加载预训练模型：** 加载预训练的CNN模型及其权重。通常可以使用所选的深度学习框架来完成这一步。
> 4. **前向传播：** 通过前向传播，将经过预处理的图像传递到CNN模型中。此传递的输出将是来自模型的一个或多个层的特征映射。
> 5. **提取特征：** 从您感兴趣的层中提取特征映射。这些特征映射捕捉了输入图像的不同抽象层次。
> 6. **后处理特征（如果必要）：** 根据您的具体用例，您可能需要对提取的特征进行后处理。例如，您可以将特征映射展平以创建特征向量，或应用降维技术，如主成分分析（PCA）。
> 7. **将特征用于任务：** 您随后可以将计算的CNN特征用于各种计算机视觉任务，如通过将其馈送到分类器进行图像分类，通过将其与区域提出方法结合来进行目标检测，或用于其他任务，如图像检索或分割。
>
> 需要注意的是，选择从哪个层提取特征可以显著影响捕捉到的信息质量和类型。较低层捕捉低级特征，如边缘和纹理，而较高层捕捉更抽象和对象特定的特征。层的选择取决于您特定任务的要求。
>
> 总的来说，计算CNN特征是许多计算机视觉应用中的基本步骤，它充分利用了预训练深度神经网络的表示学习能力。

**缺点：**

- 重复计算，每个region proposal，都需要经过一个AlexNet特征提取，为所有的RoI（region of interest）提取特征大约花费47秒，占用空间
- selective search方法生成region proposal，对一帧图像，需要花费2秒
- 三个模块（提取、分类、回归）是分别训练的，并且在训练时候，对于存储空间消耗较大

#### 2.Fast R-CNN

**定义：**

Fast R-CNN是基于R-CNN和SPPnets进行的改进。SPPnets，其创新点在于只进行一次图像特征提取（而不是每个候选区域计算一次），然后根据算法，将候选区域特征图映射到整张图片特征图中。

<img src="/Users/huangqiuzhao/python/yoloRefine/md文件/img/目标检测简介/截屏2023-10-28 21.55.48.png" style="zoom:50%;" />

**流程：**

- 使用selective search生成region proposal，大约2000个左右区域候选框
- (joint training)缩放图片的scale得到图片金字塔，FP得到conv5的特征金字塔
- (joint training)对于每个scale的每个ROI，求取映射关系，在conv5中剪裁出对应的patch。并用一个单层的SSP layer来统一到一样的尺度（对于AlexNet是6*6）
- (joint training) 继续经过两个全连接得到特征，这特征又分别共享到两个新的全连接，连接上两个优化目标。第一个优化目标是分类，使用softmax，第二个优化目标是bbox regression，使用了一个平滑的L1-loss
- 测试时需要加上NMS处理：利用窗口得分分别对每一类物体进行非极大值抑制提出重叠建议框，最终得到每个类别中回归修正后的得分最高的窗口

**改进：**

- 和RCNN相比，训练时间从84小时减少为9.5小时，测试时间从47秒减少为0.32秒。在VGG16上，Fast RCNN训练速度是RCNN的9倍，测试速度是RCNN的213倍；训练速度是SPP-net的3倍，测试速度是SPP-net的3倍
- Fast RCNN在PASCAL VOC 2007上准确率相差无几，约在66~67%之间
- 加入RoI Pooling，采用一个神经网络对全图提取特征
- 在网络中加入了多任务函数边框回归，实现了端到端的训练

**缺点：**

- 依旧采用selective search提取region proposal（耗时2~3秒，特征提取耗时0.32秒）
- 无法满足实时应用，没有真正实现端到端训练测试
- 利用了GPU，但是region proposal方法是在CPU上实现的

#### 3.Faster RCNN

**定义：**

经过R-CNN和Fast-RCNN的积淀，Ross B.Girshick在2016年提出了新的Faster RCNN，在结构上将特征抽取、region proposal提取， bbox regression，分类都整合到了一个网络中，使得综合性能有较大提高，在检测速度方面尤为明显。
<img src="/Users/huangqiuzhao/python/yoloRefine/md文件/img/目标检测简介/截屏2023-10-28 22.03.38.png" style="zoom:50%;" />

















